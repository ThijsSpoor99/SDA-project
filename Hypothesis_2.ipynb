{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bilt = pd.read_csv('Data/de_bilt_weather.csv')\n",
    "\n",
    "#shift days so that the first day starts from zero\n",
    "df_bilt['days'] = df_bilt['days'] - df_bilt['days'].min()\n",
    "\n",
    "variables = ['cloud_cover', 'wind_speed', 'wind_gust', 'humidity',\n",
    "             'pressure', 'global_radiation', 'precipitation', 'sunshine', \n",
    "             'temp_mean', 'temp_min', 'temp_max'] \n",
    "\n",
    "n_var = len(variables) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training on year of data, testing on 10 days\n",
    "train_range = 365\n",
    "test_range = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting data with shape (n_var, train_range+test_range)\n",
    "data = []\n",
    "for variable_name in variables:\n",
    "    data.append(df_bilt[variable_name][:train_range + test_range])\n",
    "data = np.vstack(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spliting training and test sets\n",
    "train_data = data[:, :train_range]   \n",
    "test_data = data[:, train_range:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cost function for the optimizer\n",
    "def var_initial_norm(params, data, means, n_var):\n",
    "    c = params[:n_var]\n",
    "    matrix = params[n_var:].reshape(n_var, n_var)\n",
    "    prediction = c[:, None] + matrix @ data[:, :-1]\n",
    "    residuals = data[:, 1:] - prediction\n",
    "    return np.linalg.norm(residuals / means[:, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize c and M to zero\n",
    "params = np.zeros(n_var + n_var**2)\n",
    "means = np.mean(train_data, axis=1)\n",
    "\n",
    "#Scipy's optimizer fits model parameters by minimizing cost function\n",
    "result = scipy.optimize.minimize(var_initial_norm, params, method='Powell', args=(train_data, means, n_var))\n",
    "\n",
    "#Represents the fitted intercepts and coefficient matrix\n",
    "c_var = result.x[:n_var]\n",
    "M_var = result.x[n_var:].reshape(n_var, n_var)\n",
    "\n",
    "#Calculate residuals of fitted model\n",
    "residuals = train_data[:, 1:] - (c_var[:, None] + M_var @ train_data[:, :-1])\n",
    "\n",
    "#Generating uncertainty in predictions\n",
    "std_var = np.std(residuals, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Produces predictions for next day given today, fits model plus normally distributed noise for uncertainty.\n",
    "def weather_var(x, c, M, std):\n",
    "    return c + M @ x + np.random.normal(0, std)\n",
    "\n",
    "#Time indices for training and testing\n",
    "t_train_data = np.arange(train_range)\n",
    "t_test_data = np.arange(train_range, train_range + test_range)\n",
    "\n",
    "#Number of simulation runs to capture uncertainty\n",
    "prediction_list = []\n",
    "n_predictions = 1000 \n",
    "\n",
    "for j in range(n_predictions):\n",
    "    #First test day is initial condition\n",
    "    prediction = [test_data[:, 0]]\n",
    "    #Predict forward for remaining test days\n",
    "    for _ in t_test_data[1:]:\n",
    "        prediction.append(weather_var(prediction[-1], c_var, M_var, std_var))\n",
    "    prediction = np.array(prediction).T\n",
    "    prediction_list.append(prediction)\n",
    "\n",
    "#List of predictions converting to array with shape (n_predictions, n_var, test_range)\n",
    "prediction_matrix = np.array(prediction_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#period analyzed is yearly\n",
    "period = train_range\n",
    "\n",
    "#Stores R^2 yearly seasonality of each variable\n",
    "seasonality_results = []\n",
    "\n",
    "for var in variables:\n",
    "    variable_data = df_bilt[var].values\n",
    "    \n",
    "    #Compute how many full seasonal cycles fit into the data\n",
    "    full_cycles = len(variable_data) // period\n",
    "    \n",
    "    #Trim data to full cycles only, so for 3654 to 3650\n",
    "    trim_len = full_cycles * period\n",
    "    trimmed_data = variable_data[:trim_len]\n",
    "    \n",
    "    #Reshaping trimmed data so that each row represents one full cycle, shape = (10, 365)\n",
    "    data_matrix = trimmed_data.reshape(full_cycles, period)\n",
    "    \n",
    "    #Find average of seasonal fluctuations (average over all cycles for each day in the cycle)\n",
    "    seasonalality = np.mean(data_matrix, axis = 0) \n",
    "    \n",
    "    #Reconstruct a seasonal-only signal by repeating the seasonalality measure as many times as full cycles\n",
    "    seasonal_signal = np.tile(seasonalality, full_cycles)\n",
    "    \n",
    "    #How well does seasonal only signal capture the true data \n",
    "    residuals = trimmed_data - seasonal_signal\n",
    "    SS_res = np.sum(residuals**2)\n",
    "    SS_tot = np.sum((trimmed_data - np.mean(trimmed_data))**2)\n",
    "    #fraction of the variability explained by the seasonal pattern\n",
    "    R_squared = 1 - (SS_res / SS_tot)\n",
    "    \n",
    "    seasonality_results.append((var, R_squared))\n",
    "\n",
    "#Sort by R^2 in descending order \n",
    "seasonality_results.sort(key = lambda x: x[1], reverse = True)\n",
    "print(\"Variables ranked by seasonality strength (R^2):\")\n",
    "for var, r2 in seasonality_results:\n",
    "    print(f\"{var}: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Based on seasonality results\n",
    "seasonal_vars = ['temp_max', 'temp_mean', 'global_radiation', 'temp_min', 'sunshine']\n",
    "non_seasonal_vars = ['precipitation', 'cloud_cover', 'wind_gust', 'pressure', 'humidity', 'wind_speed']\n",
    "\n",
    "#Storing indices from data of respective groups\n",
    "seasonal_indices = [variables.index(var) for var in seasonal_vars]\n",
    "non_seasonal_indices = [variables.index(var) for var in non_seasonal_vars]\n",
    "\n",
    "#Given var estimated c_var and M_var of a previous days x vector return todays prediciton without noise\n",
    "def deterministic_forecast(x, c, M):\n",
    "    return c + M @ x\n",
    "\n",
    "#Stores the forecasts for the entire test range starting with the yesterdays actual data as the initial\n",
    "det_predictions = [test_data[:, 0]]\n",
    "\n",
    "#For each subsequent test day, forecast using the previous days predicted values\n",
    "for t in t_test_data[1:]:\n",
    "    det_predictions.append(deterministic_forecast(det_predictions[-1], c_var, M_var))\n",
    "\n",
    "\n",
    "#Convert from list of arrays to single array \n",
    "det_predictions = np.array(det_predictions).T\n",
    "\n",
    "#Forecast error \n",
    "errors = test_data - det_predictions\n",
    "\n",
    "#RMSE calc for each variable across the full test period\n",
    "rmse = np.sqrt(np.mean(errors**2, axis = 1))\n",
    "\n",
    "#Extract RMSEs for the seasonal and non-seasonal groups separately\n",
    "seasonal_rmse = rmse[seasonal_indices]\n",
    "non_seasonal_rmse = rmse[non_seasonal_indices]\n",
    "\n",
    "def welch_ttest(x, y):\n",
    "\n",
    "    #sample lengths, means, variances\n",
    "    nx, ny = len(x), len(y)\n",
    "    mean_x, mean_y = np.mean(x), np.mean(y)\n",
    "    var_x, var_y = np.var(x, ddof = 1), np.var(y, ddof = 1)\n",
    "\n",
    "    #Find Welchs t-stat\n",
    "    t_stat = (mean_x - mean_y) / math.sqrt(var_x/nx + var_y/ny)\n",
    "\n",
    "    #Approximate p-value using the cdf of a standard normal distribution\n",
    "    def normal_cdf(z):\n",
    "        return 0.5 * (1.0 + math.erf(z / math.sqrt(2)))\n",
    "\n",
    "    #Two-sided p-value\n",
    "    p_value = 2.0 * (1.0 - normal_cdf(abs(t_stat)))\n",
    "\n",
    "    return t_stat, p_value\n",
    "\n",
    "t_stat, p_value = welch_ttest(seasonal_rmse, non_seasonal_rmse)\n",
    "\n",
    "print(\"Seasonal RMSE:\", seasonal_rmse)\n",
    "print(\"Non-Seasonal RMSE:\", non_seasonal_rmse)\n",
    "print(\"T-test statistic:\", t_stat)\n",
    "print(\"P-value:\", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_plot = [seasonal_rmse, non_seasonal_rmse]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.boxplot(data_to_plot, tick_labels=['Seasonal', 'Non-Seasonal'])\n",
    "ax.set_ylabel('RMSE')\n",
    "ax.set_title(f'Distribution of RMSE for Seasonal vs Non-Seasonal Variables {train_range} Days')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
